{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1632753014316,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "k1MIGnhW89H7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 10:51:58.495082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from numpy.fft import *\n",
    "from numpy.random import seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from transforms3d.axangles import axangle2mat\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3103,
     "status": "ok",
     "timestamp": 1632753017417,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "P_FTNGYJ89PW"
   },
   "outputs": [],
   "source": [
    "# data load\n",
    "# path 변수를 적절히 변경\n",
    "x_train_path = os.path.join('data/train_features.csv')\n",
    "y_train_path = os.path.join('data/train_labels.csv')\n",
    "x_test_path = os.path.join('data/test_features.csv')\n",
    "sub_path = os.path.join('data/sample_submission.csv')\n",
    "\n",
    "train = pd.read_csv(x_train_path)\n",
    "train_label = pd.read_csv(y_train_path)\n",
    "test = pd.read_csv(x_test_path)\n",
    "sub = pd.read_csv(sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jerk_signal(signal, dt=0.02): \n",
    "        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])\n",
    "    \n",
    "    \n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal\n",
    "\n",
    "\n",
    "def feature_engineering(data_):\n",
    "    data = data_.copy()\n",
    "    data['acc_Energy']=(data['acc_x']**2+data['acc_y']**2+data['acc_z']**2)**(1/3)\n",
    "\n",
    "    data['gy_Energy']=(data['gy_x']**2+data['gy_y']**2+data['gy_z']**2)**(1/3)\n",
    "\n",
    "    data['gy_acc_Energy']=((data['gy_x']-data['acc_x'])**2+(data['gy_y']-data['acc_y'])**2+(data['gy_z']-data['acc_z'])**2)**(1/3)\n",
    "\n",
    "    data_dt=[]\n",
    "    for i in tqdm(data['id'].unique()):\n",
    "        temp=data.loc[data['id']==i]\n",
    "        for v in data.columns[2:]:\n",
    "            values=jerk_signal(temp[v].values)\n",
    "            values=np.insert(values,0,0)\n",
    "            temp.loc[:,v+'_dt']=values\n",
    "        data_dt.append(temp)\n",
    "    data = pd.concat(data_dt)\n",
    "    \n",
    "    fft=[]\n",
    "    for i in tqdm(data['id'].unique()):\n",
    "        temp=data.loc[data['id']==i]\n",
    "        for i in data.columns[2:8]:\n",
    "            temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "        fft.append(temp)\n",
    "    data=pd.concat(fft)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(data_, scaler=None):\n",
    "    data = data_\n",
    "    col = data.columns\n",
    "    \n",
    "    if scaler:\n",
    "        data.iloc[:,2:]= scaler.transform(data.iloc[:,2:])\n",
    "        data = pd.DataFrame(data = data,columns =col)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data.iloc[:,2:]= scaler.fit_transform(data.iloc[:,2:])\n",
    "        data = pd.DataFrame(data = data,columns =col)\n",
    "        \n",
    "        return data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling(data_):\n",
    "    data = data_.copy()\n",
    "    sampling = np.random.choice(data.shape[0], int(data.shape[0] * 2 / 3))\n",
    "    for j in sampling:\n",
    "        data[j] = np.roll(data[j], np.random.choice(data.shape[1]), axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "def rotation(data_):\n",
    "    data = data_.copy()\n",
    "    axis = np.random.uniform(low=-1, high=1, size=data.shape[1])\n",
    "    angle = np.random.uniform(low=-np.pi, high=np.pi)\n",
    "    return np.matmul(data, axangle2mat(axis, angle))\n",
    "\n",
    "\n",
    "def permutation(data_, nPerm=4, mSL=10):\n",
    "    data = data_.copy()\n",
    "    data_new = np.zeros(data.shape)\n",
    "    idx = np.random.permutation(nPerm)\n",
    "    bWhile = True\n",
    "    while bWhile == True:\n",
    "        segs = np.zeros(nPerm + 1, dtype=int)\n",
    "        segs[1:-1] = np.sort(np.random.randint(mSL, data.shape[0] - mSL, nPerm - 1))\n",
    "        segs[-1] = data.shape[0]\n",
    "        if np.min(segs[1:] - segs[0:-1]) > mSL:\n",
    "            bWhile = False\n",
    "    pp = 0\n",
    "    for ii in range(nPerm):\n",
    "        data_temp = data[segs[idx[ii]]:segs[idx[ii] + 1], :]\n",
    "        data_new[pp:pp + len(data_temp), :] = data_temp\n",
    "        pp += len(data_temp)\n",
    "    return data_new\n",
    "\n",
    "\n",
    "# 2:5\n",
    "# 5:\n",
    "def augmentation(data_, labels):\n",
    "    data = data_.copy()\n",
    "    \n",
    "    # rotation\n",
    "    print('rotation...')\n",
    "    ro_aug = []\n",
    "    ro_label = []\n",
    "    ro_sampling = np.random.choice(data.shape[0]//600, int((data.shape[0]//600) * 1 / 3))\n",
    "    for j in tqdm(ro_sampling):\n",
    "        columns = data.iloc[:, 2:].columns\n",
    "        temp_df = data.iloc[j*600:(j+1)*600, :2]\n",
    "        # acc\n",
    "        acc = rotation(np.array(data.iloc[j*600:(j+1)*600, 2:5]))\n",
    "        # gy\n",
    "        gy = rotation(np.array(data.iloc[j*600:(j+1)*600, 5:]))\n",
    "        \n",
    "        temp = np.concatenate([acc, gy], axis=1)\n",
    "        temp = pd.DataFrame(temp, columns=columns, index=temp_df.index)\n",
    "        temp = pd.concat([temp_df, temp], axis=1)\n",
    "        ro_label.append(labels[j])\n",
    "        ro_aug.append(temp)\n",
    "        \n",
    "    ro_aug = pd.concat(ro_aug)\n",
    "    ro_feature = feature_engineering(ro_aug)\n",
    "    ro_sc, _ = scaling(ro_feature)\n",
    "    ro_series = ro_sc.iloc[:, 2:].to_numpy().reshape(-1, 600, 18)\n",
    "    ro_series = rolling(ro_series)\n",
    "    \n",
    "    # permutation\n",
    "    print('permutation...')\n",
    "    per_aug = []\n",
    "    per_label = []\n",
    "    per_sampling = np.random.choice(data.shape[0]//600, int((data.shape[0]//600) * 1 / 3))\n",
    "    for j in tqdm(per_sampling):\n",
    "        columns = data.iloc[:, 2:].columns\n",
    "        temp_df = data.iloc[j*600:(j+1)*600, :2]\n",
    "        # acc\n",
    "        acc = permutation(np.array(data.iloc[j*600:(j+1)*600, 2:5]))\n",
    "        # gy\n",
    "        gy = permutation(np.array(data.iloc[j*600:(j+1)*600, 5:]))\n",
    "        \n",
    "        temp = np.concatenate([acc, gy], axis=1)\n",
    "        temp = pd.DataFrame(temp, columns=columns, index=temp_df.index)\n",
    "        temp = pd.concat([temp_df, temp], axis=1)\n",
    "        per_label.append(labels[j])\n",
    "        per_aug.append(temp)\n",
    "    \n",
    "    per_aug = pd.concat(per_aug)\n",
    "    per_feature = feature_engineering(per_aug)\n",
    "    per_sc, _ = scaling(per_feature)\n",
    "    per_series = per_sc.iloc[:, 2:].to_numpy().reshape(-1, 600, 18)\n",
    "    per_series = rolling(per_series)\n",
    "    \n",
    "    origin_feature = feature_engineering(data)\n",
    "    origin_sc, _ = scaling(origin_feature)\n",
    "    origin_series = origin_sc.iloc[:, 2:].to_numpy().reshape(-1, 600, 18)\n",
    "    \n",
    "    final = np.concatenate([origin_series, ro_series, per_series], axis=0)\n",
    "    final_label = np.concatenate([labels, ro_label, per_label], axis=0)\n",
    "    \n",
    "    return final, final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1632753117451,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "PCCxRppM8-J5"
   },
   "outputs": [],
   "source": [
    "def ids_26(label):\n",
    "    mask = label['label'] == 26\n",
    "    ids = label.loc[mask, 'id'].to_numpy()\n",
    "    \n",
    "    return ids\n",
    "\n",
    "\n",
    "def make_split_dataset(train, ids, labels):\n",
    "    final_list = []\n",
    "    columns = train.columns\n",
    "    train = train.to_numpy().reshape(-1, 600, 8)\n",
    "    \n",
    "    k_split = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "    \n",
    "    except_mask = np.setdiff1d(np.array(range(3125)), ids)\n",
    "    except_train = train[except_mask]\n",
    "    except_label = labels[except_mask]\n",
    "    \n",
    "    train_26 = train[ids]\n",
    "\n",
    "    for _, fold in k_split.split(train_26):\n",
    "        temp_train = train_26[fold]\n",
    "        temp_label = np.array([26] * len(temp_train))\n",
    "        \n",
    "        temp_train = np.concatenate([temp_train, except_train], axis=0)\n",
    "        temp_label = np.concatenate([temp_label, except_label], axis=0)\n",
    "        \n",
    "        temp_train = pd.DataFrame(temp_train.reshape(temp_train.shape[0] * 600, -1), columns=columns)\n",
    "        print(temp_train.shape)\n",
    "        final_list.append([temp_train, temp_label])\n",
    "        \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1632753126299,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "yowGy5Ep8-c3"
   },
   "outputs": [],
   "source": [
    "# dataset과 validation set을 만들어 주는 함수\n",
    "# validation set은 shuffle 적용 x\n",
    "def make_train(series_data, labels):\n",
    "    cat_y = tf.keras.utils.to_categorical(labels)\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((series_data, cat_y))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000, seed=42)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset\n",
    "\n",
    "def make_val(series_data, labels):\n",
    "    cat_y = tf.keras.utils.to_categorical(labels)\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((series_data, cat_y))\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rolling(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Rolling, self).__init__()\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.roll(inputs, shift=np.random.randint(0, 599), axis=1)\n",
    "        else:\n",
    "            return inputs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1632753126300,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "hTnuw0XG8-h-"
   },
   "outputs": [],
   "source": [
    "# 모델을 만들어 주는 함수\n",
    "# 기존 base에서 overfitting이 심해, dropout을 늘림(아직 제출은 안해봄)\n",
    "def base():\n",
    "    seed(2021)\n",
    "    tf.random.set_seed(2021)\n",
    "    model = keras.models.Sequential([\n",
    "            keras.layers.Input([600, 18]),\n",
    "            Rolling(),\n",
    "            keras.layers.Conv1D(filters=128, kernel_size=9, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Conv1D(filters=256, kernel_size=6, padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Conv1D(filters=128, kernel_size=3,padding='same'),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.GlobalAveragePooling1D(),\n",
    "            keras.layers.Dense(61, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025400, 8)\n",
      "(1025400, 8)\n",
      "(1025400, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n",
      "(1024800, 8)\n"
     ]
    }
   ],
   "source": [
    "ids = ids_26(train_label)\n",
    "data_list = make_split_dataset(train, ids, train_label['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1632753126300,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "eo4fxzysUtPz"
   },
   "outputs": [],
   "source": [
    "# checkpoint path\n",
    "# 중간중간 모델의 weight를 저장할 경로 설정\n",
    "ckpt_name = 'random_sampling.hdf5'\n",
    "checkpoint_dir_path = os.path.join('checkpoint')\n",
    "checkpoint_path = os.path.join('checkpoint', ckpt_name)\n",
    "\n",
    "# check checkpoint paht\n",
    "# 경로가 없으면 생성함\n",
    "if not(os.path.exists(checkpoint_dir_path)):\n",
    "    os.mkdir(checkpoint_dir_path)\n",
    "\n",
    "# callback 함수 목록\n",
    "callbacks_list = [\n",
    "    # 매 epoch 마다 val_loss를 체크하여 가장 낮은 상태의 weight를 저장\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    # 8번 동안 val_loss의 향상이 없으면 훈련 종료\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1, \n",
    "        patience=8\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 471350,
     "status": "error",
     "timestamp": 1632753597647,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "5FdTcrg2UtVN",
    "outputId": "27b5b2d2-84be-42f3-aa5e-b3da5bc8324a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 513/513 [00:03<00:00, 137.53it/s]\n",
      "100%|████████████████████████████████████████| 513/513 [00:00<00:00, 951.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation...\n",
      "rotation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 398/398 [00:00<00:00, 1914.38it/s]\n",
      "100%|████████████████████████████████████████| 333/333 [00:02<00:00, 131.44it/s]\n",
      "100%|████████████████████████████████████████| 333/333 [00:00<00:00, 959.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 398/398 [00:00<00:00, 1724.15it/s]\n",
      "100%|████████████████████████████████████████| 336/336 [00:02<00:00, 128.73it/s]\n",
      "100%|███████████████████████████████████████| 336/336 [00:00<00:00, 1005.61it/s]\n",
      "100%|██████████████████████████████████████| 1196/1196 [00:08<00:00, 133.74it/s]\n",
      "100%|██████████████████████████████████████| 1196/1196 [00:01<00:00, 863.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 10:57:30.995828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-08 10:57:31.097656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 28ms/step - loss: 3.9666 - accuracy: 0.0728 - val_loss: 981.0885 - val_accuracy: 0.0156\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 3.7184 - accuracy: 0.1124 - val_loss: 506.0768 - val_accuracy: 0.0136\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.5693 - accuracy: 0.1466 - val_loss: 659.0518 - val_accuracy: 0.0253\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 3.4534 - accuracy: 0.1772 - val_loss: 492.4740 - val_accuracy: 0.0234\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.3705 - accuracy: 0.2144 - val_loss: 726.3790 - val_accuracy: 0.0273\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.2848 - accuracy: 0.2294 - val_loss: 708.4688 - val_accuracy: 0.0429\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.2250 - accuracy: 0.2500 - val_loss: 761.0492 - val_accuracy: 0.0273\n",
      "Epoch 8/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 3.1536 - accuracy: 0.2626\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.1520 - accuracy: 0.2636 - val_loss: 905.7086 - val_accuracy: 0.0487\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.0633 - accuracy: 0.2771 - val_loss: 912.7115 - val_accuracy: 0.0409\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 3.0361 - accuracy: 0.2856 - val_loss: 916.6606 - val_accuracy: 0.0390\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 2.9819 - accuracy: 0.2977 - val_loss: 989.9561 - val_accuracy: 0.0370\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.9571 - accuracy: 0.3082\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 2.9571 - accuracy: 0.3082 - val_loss: 847.2991 - val_accuracy: 0.0175\n",
      "Epoch 00012: early stopping\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9599 - accuracy: 0.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████▎         | 388/513 [00:02<00:00, 133.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30140/215459353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30140/1564124232.py\u001b[0m in \u001b[0;36mfeature_engineering\u001b[0;34m(data_)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjerk_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdata_dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                         )\n\u001b[0;32m-> 1601\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m                         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;31m# maybe partial set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m         \u001b[0mtake_split_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0;31m# if there is only one block/type, still have to take split path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_inplace_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5203\u001b[0m         \"\"\"\n\u001b[1;32m   5204\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5205\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5240\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5242\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SingleBlockManager\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;31m# TODO: can we avoid this?  it isn't cheap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kw-ai/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "k = 5\n",
    "split = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "for data in data_list:\n",
    "    series = data[0].to_numpy().reshape(-1, 600, 8)\n",
    "    \n",
    "    train, val, y_train, y_val = train_test_split(series, data[1], train_size=0.7, stratify=data[1], random_state=42)\n",
    "    \n",
    "    train_data = pd.DataFrame(train.reshape(train.shape[0]*600, -1), columns=data[0].columns)\n",
    "    val_data = pd.DataFrame(val.reshape(val.shape[0]*600, -1), columns=data[0].columns)\n",
    "    \n",
    "    val_data = feature_engineering(val_data)\n",
    "    val_data = val_data.iloc[:, 2:].to_numpy().reshape(-1, 600, 18)\n",
    "    \n",
    "    print('augmentation...')\n",
    "    aug_data, aug_y = augmentation(train_data, y_train)\n",
    "    y_train = np.concatenate([y_train, y_train, y_train], axis=0)\n",
    "    \n",
    "    #train_data = feature_engineering(train_data)\n",
    "    #train_data = train_data.iloc[:, 2:].to_numpy().reshape(-1, 600, 18)\n",
    "    \n",
    "    train_dataset = make_train(aug_data, aug_y)\n",
    "    #train_dataset = make_train(train_data, aug_y)\n",
    "    val_dataset = make_val(val_data, y_val)\n",
    "    model = base()\n",
    "\n",
    "    model.fit(train_dataset, validation_data=val_dataset, callbacks=callbacks_list, epochs=1000)\n",
    "    #model.fit(train_dataset, epochs=1000)\n",
    "    #model.load_weights(checkpoint_path)\n",
    "    model.evaluate(train_dataset)\n",
    "    #model.evaluate(val_dataset)\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1632753597413,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "r0qToCt0UtZy"
   },
   "outputs": [],
   "source": [
    "# 결과 생성\n",
    "pred_list = []    # 예측 결과를 담을 리스트\n",
    "for model in models:\n",
    "    pred = model.predict(series_test)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "pred = np.mean(pred_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1632753597413,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "QmWcN5c2Utea"
   },
   "outputs": [],
   "source": [
    "# 제출물 생성\n",
    "sub.iloc[:, 1:] = pred\n",
    "sub.to_csv('overfit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1632753597414,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "BxddAc1CUuLu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1632753597414,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "EuPumb4RUuRL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1632753597415,
     "user": {
      "displayName": "정진우",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05017758655145019300"
     },
     "user_tz": -540
    },
    "id": "oaUkQ0IYc6ld"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPQ+P5ZoAiHAYL4HOeJ/p4Q",
   "collapsed_sections": [],
   "name": "randomsampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kw-ai",
   "language": "python",
   "name": "kw-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
